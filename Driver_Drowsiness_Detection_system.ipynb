{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jddeBJkqCWJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cc46ed8-7d07-4a9d-b74c-6005b08a596a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parameters\n",
            "  Downloading parameters-0.2.1.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: parameters\n",
            "  Building wheel for parameters (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parameters: filename=parameters-0.2.1-py3-none-any.whl size=24749 sha256=952b2b87d4d75636badcc8f3a86884041953ed2dda87725588e30161785cbbfd\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/6d/66/480b6c919eda69e55fe79ccf9d278a3d48e4d2737b5ad9ff85\n",
            "Successfully built parameters\n",
            "Installing collected packages: parameters\n",
            "Successfully installed parameters-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install parameters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance"
      ],
      "metadata": {
        "id": "57EMC7IvE6Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imutils import face_utils as face"
      ],
      "metadata": {
        "id": "LzpHNHMmQbTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pygame import mixer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lyjZV9LQfde",
        "outputId": "f1a3eb36-6633-4d07-d8c3-c2423b5ab969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pygame 2.5.2 (SDL 2.28.2, Python 3.10.12)\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DaZcaPBJQimm",
        "outputId": "54790826-4069-45aa-ebad-79b34fc487d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (2.5.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "p5-hlqifQlD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dlib"
      ],
      "metadata": {
        "id": "OlRnLLxhQr3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "mXARqj7PQt54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import imutils"
      ],
      "metadata": {
        "id": "csGjlPc1Qwyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_max_area_rect(rects):\n",
        "  if len(rects)==0: return\n",
        "  areas=[]\n",
        "  for rect in rects:\n",
        "    areas.append(rect.area())\n",
        "  return rects[areas.index(max(areas))]"
      ],
      "metadata": {
        "id": "_dlH8LcJQyjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_eye_aspect_ratio(eye):\n",
        "  vertical_1 = distance.euclidean(eye[1],eye[5])\n",
        "  vertical_2 = distance.euclidean(eye[2],eye[4])\n",
        "  horizontal = distance.euclidean(eye[0],eye[3])\n",
        "  return (vertical_1+vertical_2)/(horizontal*2)"
      ],
      "metadata": {
        "id": "ggKfLZ6gRRVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mouth_aspect_ratio(mouth):\n",
        "  horizontal = distance.euclidean(mouth[0],mouth[4])\n",
        "  vertical=0\n",
        "  for coord in range(1,4):\n",
        "    vertical+=distance.euclidean(mouth[coord],mouth[8-coord])\n",
        "  return vertical/(horizontal*3)"
      ],
      "metadata": {
        "id": "dMRSSmVIRwfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def facial_processing():\n",
        "  # mixer.init()\n",
        "  distraction_initialized = False\n",
        "  eye_initialized = False\n",
        "  mouth_initialized = False\n",
        "\n",
        "  detector = dlib.get_frontal_face_detector()\n",
        "  predictor = dlib.shape_predictor(shape_predictor_path)\n",
        "\n",
        "  def facial_processing():\n",
        "    mixer.init()\n",
        "    distracton_initlized = False\n",
        "    eye_initialized      = False\n",
        "    mouth_initialized    = False\n",
        "\n",
        "    detector    = dlib.get_frontal_face_detector()\n",
        "    predictor   = dlib.shape_predictor(shape_predictor_path)\n",
        "\n",
        "    ls,le = face.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n",
        "    rs,re = face.FACIAL_LANDMARKS_IDXS[\"right_eye\"]\n",
        "\n",
        "    cap=cv2.VideoCapture(0)\n",
        "\n",
        "    fps_couter=0\n",
        "    fps_to_display='initializing...'\n",
        "    fps_timer=time.time()\n",
        "    while True:\n",
        "        _ , frame=cap.read()\n",
        "        fps_couter+=1\n",
        "        frame = cv2.flip(frame, 1)\n",
        "        if time.time()-fps_timer>=1.0:\n",
        "            fps_to_display=fps_couter\n",
        "            fps_timer=time.time()\n",
        "            fps_couter=0\n",
        "        cv2.putText(frame, \"FPS :\"+str(fps_to_display), (frame.shape[1]-100, frame.shape[0]-10),\\\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "\n",
        "        #frame = imutils.resize(frame, width=900)\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        rects = detector(gray, 0)\n",
        "        rect=get_max_area_rect(rects)\n",
        "\n",
        "        if rect!=None:\n",
        "\n",
        "            distracton_initlized=False\n",
        "\n",
        "            shape = predictor(gray, rect)\n",
        "            shape = face.shape_to_np(shape)\n",
        "\n",
        "            leftEye = shape[ls:le]\n",
        "            rightEye = shape[rs:re]\n",
        "            leftEAR = get_eye_aspect_ratio(leftEye)\n",
        "            rightEAR = get_eye_aspect_ratio(rightEye)\n",
        "\n",
        "            inner_lips=shape[60:68]\n",
        "            mar=get_mouth_aspect_ratio(inner_lips)\n",
        "\n",
        "            eye_aspect_ratio = (leftEAR + rightEAR) / 2.0\n",
        "\n",
        "            leftEyeHull = cv2.convexHull(leftEye)\n",
        "            rightEyeHull = cv2.convexHull(rightEye)\n",
        "            cv2.drawContours(frame, [leftEyeHull], -1, (255, 255, 255), 1)\n",
        "            cv2.drawContours(frame, [rightEyeHull], -1, (255, 255, 255), 1)\n",
        "            lipHull = cv2.convexHull(inner_lips)\n",
        "            cv2.drawContours(frame, [lipHull], -1, (255, 255, 255), 1)\n",
        "\n",
        "            cv2.putText(frame, \"EAR: {:.2f} MAR{:.2f}\".format(eye_aspect_ratio,mar), (10, frame.shape[0]-10),\\\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
        "\n",
        "            if eye_aspect_ratio < EYE_DROWSINESS_THRESHOLD:\n",
        "\n",
        "                if not eye_initialized:\n",
        "                    eye_start_time= time.time()\n",
        "                    eye_initialized=True\n",
        "\n",
        "                if time.time()-eye_start_time >= EYE_DROWSINESS_INTERVAL:\n",
        "                    alarm_type=0\n",
        "                    cv2.putText(frame, \"YOU ARE SLEEPY...\\nPLEASE TAKE A BREAK!\", (10, 20),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "                    if  not distracton_initlized and not mouth_initialized and not mixer.music.get_busy():\n",
        "                        mixer.music.load(alarm_paths[alarm_type])\n",
        "                        mixer.music.play()\n",
        "            else:\n",
        "                eye_initialized=False\n",
        "                if not distracton_initlized and not mouth_initialized and mixer.music.get_busy():\n",
        "                    mixer.music.stop()\n",
        "\n",
        "\n",
        "            if mar > MOUTH_DROWSINESS_THRESHOLD:\n",
        "\n",
        "                if not mouth_initialized:\n",
        "                    mouth_start_time= time.time()\n",
        "                    mouth_initialized=True\n",
        "\n",
        "                if time.time()-mouth_start_time >= MOUTH_DROWSINESS_INTERVAL:\n",
        "                    alarm_type=0\n",
        "                    cv2.putText(frame, \"YOU ARE YAWNING...\\nDO YOU NEED A BREAK?\", (10, 40),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "                    if not mixer.music.get_busy():\n",
        "                        mixer.music.load(alarm_paths[alarm_type])\n",
        "                        mixer.music.play()\n",
        "            else:\n",
        "                mouth_initialized=False\n",
        "                if not distracton_initlized and not eye_initialized and mixer.music.get_busy():\n",
        "                    mixer.music.stop()\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            alarm_type=1\n",
        "            if not distracton_initlized:\n",
        "                distracton_start_time=time.time()\n",
        "                distracton_initlized=True\n",
        "\n",
        "            if time.time()- distracton_start_time> DISTRACTION_INTERVAL:\n",
        "\n",
        "                cv2.putText(frame, \"EYES ON ROAD\", (10, 20),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "                if not eye_initialized and not mouth_initialized and not  mixer.music.get_busy():\n",
        "                    mixer.music.load(alarm_paths[alarm_type])\n",
        "                    mixer.music.play()\n",
        "\n",
        "        cv2.imshow(\"Frame\", frame)\n",
        "        key = cv2.waitKey(5)&0xFF\n",
        "        if key == ord(\"q\"):\n",
        "            break\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    cap.release()\n",
        "\n",
        "if __name__=='main':\n",
        "    facial_processing()"
      ],
      "metadata": {
        "id": "smN5MBH5SPaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FyyXlroLIYgN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}